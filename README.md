# Big Data Analytics Lab - IT-513  
**Mentor**: Dr. Neeraj Kumar  
**Institution**: NIT Jalandhar  

This repository contains **10 experiments** conducted as part of the **Big Data Analytics Lab (IT-513)** under the guidance of **Dr. Neeraj Kumar**. Each experiment includes a step-by-step guide, code implementation, and output screenshots, all documented in individual PDF files.  

## Lab Exercises  

### 1. Hadoop Setup and Monitoring  
- **Description**:  
  Setting up Hadoop in pseudo-distributed and fully distributed modes and using web-based tools for monitoring.  
- **Details**: [Experiment 1 PDF](https://github.com/ankigit1/Big-Data-Analytics-Lab-Work-IT-513/blob/main/LAB%201.pdf)  

### 2. Hadoop File Management and Benchmarking  
- **Description**:  
  Managing files in Hadoop (add, retrieve, delete) and stress testing a Hadoop cluster.  
- **Details**: [Experiment 2 PDF](https://github.com/ankigit1/Big-Data-Analytics-Lab-Work-IT-513/blob/main/LAB%202.pdf)  

### 3. MapReduce - Word Count and Word Search  
- **Description**:  
  Implementing a Word Count MapReduce program and performing word search using MapReduce.  
- **Details**: [Experiment 3 PDF](https://github.com/ankigit1/Big-Data-Analytics-Lab-Work-IT-513/blob/main/LAB%203.pdf)  

### 4. Stop Word Elimination  
- **Description**:  
  Removing stop words from a large text file based on a predefined list.  
- **Details**: [Experiment 4 PDF](https://github.com/ankigit1/Big-Data-Analytics-Lab-Work-IT-513/blob/main/LAB%204.pdf)  

### 5. Weather Data Analysis  
- **Description**:  
  Analyzing [weather data](https://drive.google.com/file/d/1DYGnJuf-RFtJ7HMw0J-xgE0S8I1Q3oiO/view?usp=sharing) using MapReduce to find average, maximum, and minimum temperatures and filter specific data.  
- **Details**: [Experiment 5 PDF](https://github.com/ankigit1/Big-Data-Analytics-Lab-Work-IT-513/blob/main/LAB%205.pdf)  

### 6. Purchases Data Analysis  
- **Description**:  
  Analyzing the [Purchases dataset](https://www.kaggle.com/datasets/dsfelix/purchasestxt) for sales breakdown, highest sales, and total sales across multiple stores.  
- **Details**: [Experiment 6 PDF](https://github.com/ankigit1/Big-Data-Analytics-Lab-Work-IT-513/blob/main/LAB%206.pdf)  

### 7. Pig Scripting  
- **Description**:  
  Writing Pig Latin scripts for sorting, grouping, joining, projecting, and filtering data.  
- **Details**: [Experiment 7 PDF](https://github.com/ankigit1/Big-Data-Analytics-Lab-Work-IT-513/blob/main/LAB%207.pdf)  

### 8. TF-IDF with Pig  
- **Description**:  
  Calculating the TF-IDF value for a book dataset using Pig Latin scripts.  
- **Details**: [Experiment 8 PDF](https://github.com/ankigit1/Big-Data-Analytics-Lab-Work-IT-513/blob/main/LAB%208.pdf)  

### 9. Hive Operations  
- **Description**:  
  Using Hive to create, alter, and drop databases, tables, views, functions, and indexes.  
- **Details**: [Experiment 9 PDF](https://github.com/ankigit1/Big-Data-Analytics-Lab-Work-IT-513/blob/main/LAB%209.pdf)  

### 10. Apache Spark Setup and Applications  
- **Description**:  
  Installing, configuring, and running Apache Spark applications using Scala.  
- **Details**: [Experiment 10 PDF](https://github.com/ankigit1/Big-Data-Analytics-Lab-Work-IT-513/blob/main/LAB%2010.pdf)  

## Repository Structure  

```
/  
|-- Experiment1.pdf  
|-- Experiment2.pdf  
|-- Experiment3.pdf  
|-- Experiment4.pdf  
|-- Experiment5.pdf  
|-- Experiment6.pdf  
|-- Experiment7.pdf  
|-- Experiment8.pdf  
|-- Experiment9.pdf  
|-- Experiment10.pdf  
|-- README.md  
```  

## How to Use  
- Each experiment is documented in its respective PDF file.  
- Open the PDF for a detailed guide on the steps, coding implementation, and output screenshots.  

## Tools and Technologies  
- **Apache Hadoop**  
- **Apache Pig**  
- **Apache Hive**  
- **Apache Spark**  
- Programming Languages: **Java, Python, Scala**  

## Key Learning Outcomes  
- Understanding Hadoop ecosystem components.  
- Implementing distributed file management and processing tasks.  
- Gaining proficiency in MapReduce, Pig, Hive, and Spark.  
- Analyzing real-world datasets and extracting actionable insights.  

Feel free to explore and learn from these experiments!  
